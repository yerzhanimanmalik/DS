{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWkADk6Njbte"
   },
   "source": [
    "# Home Assignment No. 3 ( Practice)\n",
    "\n",
    "# fMRI Deep Learning analysis\n",
    "\n",
    "* You are **HIGHLY RECOMMENDED** to read relevant documentation, e.g. for [python](https://docs.python.org/3/), [numpy](https://docs.scipy.org/doc/numpy/reference/), [matlpotlib](https://matplotlib.org/), [sklearn](https://scikit-learn.org/stable/) and [pytorch](https://pytorch.org/). Also remember that seminars, lecture slides, [Google](http://google.com) and [StackOverflow](https://stackoverflow.com/) are your close friends during this course (and, probably, whole life?).\n",
    "\n",
    "* If you want an easy life, you have to use **BUILT-IN METHODS** of `sklearn` and `pytorch` libraries, as well as ready **NN BUILDING BLOCKS** from `pytorch.nn` module, instead of writing tons of your own code. There exists a class/method for almost everything you can imagine (related to this homework).\n",
    "\n",
    "* To do this part of homework, you have to write **CODE** directly inside specified places inside notebook **CELLS**.\n",
    "\n",
    "* In some problems you are asked to provide short discussion of the results. In these cases you have to create **MARKDOWN** cell with your comments right after the corresponding code cell.\n",
    "\n",
    "* For every separate problem you can get only 0 points or maximal points for this problem. There are **NO INTERMEDIATE SCORES**. So make sure that you did everything required in the task\n",
    "\n",
    "* Your **SOLUTION** notebook **MUST BE REPRODUCIBLE**, i.e. if the reviewer decides to execute all, after all the computation he will obtain exactly the same solution (with all the corresponding plots) as in your uploaded notebook. For this purpose, we suggest to fix random `seed` or (better) define `random_state=` inside every algorithm that uses some pseudorandomness.\n",
    "\n",
    "* Your code must be clear to the reviewer. For this purpose, try to include neccessary comments inside the code. But remember: **GOOD CODE MUST BE SELF-EXPLANATORY** without any additional comments.\n",
    "\n",
    "* Many `sklearn` algorithms support multithreading (Ensemble Methods, Cross-Validation, etc.). Check if the particular algorithm has `n_jobs` parameters and set it to `-1` to use all the cores.\n",
    "\n",
    "To begin with, let's import the essential (for this assignment) libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gVxCjunbT7_h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl2AC6FQjqvY"
   },
   "source": [
    "### Lets build  the full-size fMRI classification with autoencoder-based model (10 points)\n",
    "\n",
    "#### To get maximum points you are to:\n",
    " 1. train an autoencoder model **(2 pts)** and attach the trained model with model.state_dict **(1 pts)**.\n",
    "\n",
    " 2. provide code for encoding fMRI sequences into sequences of 1D latent vectors **(1 pts)**.\n",
    "\n",
    " 3. train three (separate) RNN models on the encoded fMRI sequences to detect SCHZ, BIPOLAR, and ADHD pathologies from CONTROL group, (**3 pts**, **1 pts** for each)\n",
    " \n",
    " 4. obtain on cross-validation ROC AUC scores not less than:\n",
    "    - **0.75** for SCHZ/CONTROL (**1 pts**)\n",
    "    - **0.68** for BIPOLAR/CONTROL (**1 pts**)\n",
    "    - **0.70** for ADHD/CONTROL (**1 pts**)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "NYAg7jwSQfKn",
    "outputId": "391bb7fa-33cf-45bd-9132-c71093f9c127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.4.0\n",
      "Not using GPU\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "if use_cuda:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Not using GPU\")\n",
    "\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDkEfdawU3vd"
   },
   "source": [
    "#### Part 1: train a convolutional **autoencoder model** on brain images from fMRI time series. \n",
    "\n",
    "1. Load training and validation data.\n",
    "2. Implement an autoencoder model.\n",
    "3. Train the autoencoder to a satisfactory reconstruction quality.\n",
    "4. Save the model.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* The best is to train autoencoder on the brain images sampled from the whole fMRI sequence at random time steps. However, for the sake of more fast and memory-efficient training, here you should use prepared tensor datasets:\n",
    "    * **`tensors_train`** - tensor of brain images taken at the **0**th time step of each fMRI series - for **training**,\n",
    "    * **`tensors_val`** - tensor of brain images taken at the **16**th time step of each fMRI series - for **validation**.\n",
    "\n",
    "* Changes in functional activity in fMRI images may account only for a small fraction of the total signal. Therefore, it may be important to achieve a sufficiently high reconstruction quality to ensure that they are properly reflected in a latent representation.\n",
    "\n",
    "* Try to avoid too complex and wide autoencoder architecture - it would be very likely overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zACrFFoNSFQg"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/NeuroML/tensors_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-95727778994e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load tensors with training and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensors_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/NeuroML/tensors_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtensors_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/NeuroML/tensors_val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/NeuroML/tensors_train'"
     ]
    }
   ],
   "source": [
    "# Load tensors with training and validation data\n",
    "\n",
    "tensors_train = torch.load(\"/content/drive/My Drive/NeuroML/tensors_train\")\n",
    "tensors_val = torch.load(\"/content/drive/My Drive/NeuroML/tensors_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gPzJ2SuRTKX"
   },
   "outputs": [],
   "source": [
    "# implement Autoencoder model\n",
    "\n",
    "class Autoencoder3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        self.encoder = ### YOUR CODE HERE\n",
    "        self.decoder = ### YOUR CODE HERE\n",
    "        \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x) \n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x_rec = self.decoder(z)\n",
    "        return x_rec\n",
    "\n",
    "    def forward(self, x):        \n",
    "        z = self.encode(x)\n",
    "        x_rec = self.decode(z)\n",
    "        return x_rec, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYl-yERS8YBB"
   },
   "outputs": [],
   "source": [
    "# implement all needed train functions & train autoencoder\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qLvJ9RwDYWf4",
    "outputId": "4f63458d-45d3-42a1-ae12-85262e9d46b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fMRI_Autoencoder\n"
     ]
    }
   ],
   "source": [
    "# save trained autoencoder model\n",
    "\n",
    "name = \"fMRI_Autoencoder\"\n",
    "print(name)\n",
    "torch.save({\n",
    "    'epoch': 200,\n",
    "    'model_state_dict': AE.state_dict(),\n",
    "    'optimizer_state_dict': AE_opt.state_dict(),\n",
    "}, \"/content/drive/My Drive/NeuroML/{}.pth\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1S7zGCTc7kv"
   },
   "source": [
    "#### Part 2: encode the full-size fMRI sequence into a sequence of one-dimensional latent vectors with the pretrained encoder. \n",
    "\n",
    "1. Load the training data and prepare training dataset.\n",
    "2. Iterate through all fMRI sequences and transform each image in a sequence into a latent vector.\n",
    "3. Construct a tensor dataset with encoded sequences and corresponding labels.\n",
    "\n",
    "Notes:\n",
    "<!-- * Whole fMRI sequences dataset is located at `folder_path = '/content/drive/My Drive/NeuroML/func/'` -->\n",
    "* Brain images in training dataset for autoencoder were individually normalized to **(0, 1)** range. Use **`RescaleIntensity`** transform to achieve the same effect when encoding the data.\n",
    "* You do not have to use whole fMRI sequences. Probably you will find out that **64**, **128**, or **160** time steps are enough to capture important temporal patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAukEbxIdzbY"
   },
   "outputs": [],
   "source": [
    "# transforms\n",
    "import warnings\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.FloatTensor(img)\n",
    "\n",
    "class RescaleIntensity(object):\n",
    "    \"\"\"Rescale intensity values to a certain range.\n",
    "\n",
    "    Args:\n",
    "        out_min_max: Range :math:`(n_{min}, n_{max})` of output intensities.\n",
    "        percentiles: Percentile values of the input image that will be mapped\n",
    "            to :math:`(n_{min}, n_{max})`. They can be used for contrast\n",
    "            stretching, as in `this scikit-image example`_. For example,\n",
    "            Isensee et al. use ``(0.05, 99.5)`` in their `nn-UNet paper`_.\n",
    "        masking_method: See\n",
    "            :py:class:`~torchio.transforms.preprocessing.normalization_transform.NormalizationTransform`.\n",
    "        p: Probability that this transform will be applied.\n",
    "    \"\"\"\n",
    "    def __init__(self, out_min_max, percentiles=(0, 100), masking_method=None):\n",
    "#             masking_method: TypeMaskingMethod=None,\n",
    "        super().__init__()\n",
    "        self.out_min, self.out_max = out_min_max\n",
    "        self.percentiles = percentiles\n",
    "        self.masking_method = masking_method\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        if self.masking_method is None:\n",
    "            mask = torch.ones_like(sample)\n",
    "        else:\n",
    "            mask = self.masking_method(sample)\n",
    "        return self.rescale(sample, mask)\n",
    "\n",
    "    def rescale(self, tensor, mask):\n",
    "        array = tensor.numpy()\n",
    "        mask = mask.numpy()\n",
    "        values = array[mask]\n",
    "        cutoff = np.percentile(values, self.percentiles)\n",
    "        np.clip(array, *cutoff, out=array)\n",
    "        array -= array.min()  # [0, max]\n",
    "        array_max = array.max()\n",
    "        if array_max == 0:\n",
    "            message = (f'Rescaling image not possible due to division by zero')\n",
    "            warnings.warn(message)\n",
    "            return tensor\n",
    "        array /= array.max()  # [0, 1]\n",
    "        out_range = self.out_max - self.out_min\n",
    "        array *= out_range  # [0, out_range]\n",
    "        array += self.out_min  # [out_min, out_max]\n",
    "        return torch.from_numpy(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr6J2Zn18tx2"
   },
   "outputs": [],
   "source": [
    "# implement fMRI Dataset/Dataloader class\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "5xypbNE4UtXi",
    "outputId": "16869766-97a4-4392-ab94-87e4612e065c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 336516.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 image files found.\n"
     ]
    }
   ],
   "source": [
    "# load & transform whole fMRI sequences data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    RescaleIntensity((0, 1), masking_method=lambda x: x > 0),\n",
    "])\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "egRhvHxWlJh3",
    "outputId": "9a08ce2b-90ad-4e4d-80d7-3f81c5519fed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [15:45<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((262, 6144, 128), (262,))"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode fMRI sequences into the one-dimensional vector time series with pretrained autoencoder\n",
    "\n",
    "Z, Y = [], []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        x, y = dataset[i]\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        z = z.cpu().detach().numpy().reshape(len(x), -1)\n",
    "        \n",
    "        Z.append(z)\n",
    "        Y.append(y) \n",
    "Z = np.stack(Z, axis=0).transpose(0, 2, 1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "Z.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeCI1s764o7-"
   },
   "source": [
    "#### Part 3: train a RNN models on the sequence of one-dimensional latent vectors to predict each of three pathologies (SCHZ (Schizophrenia), BIPOLAR, ADHD). \n",
    "\n",
    "1. Implement a RNN model.\n",
    "2. Train RNN model and measure ROC AUC score on 3-fold cross-validation for 3 pathology vs control classification tasks. \n",
    "\n",
    "Notes:\n",
    "* Overfitting is highly probable, so you may want to experiment with various regularization strategies (dropout, weight decay).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDMaVnWxnKMv"
   },
   "outputs": [],
   "source": [
    "# implement RNN model\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "    def forward(self, x):\n",
    "      \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFg0uC3QnYt0"
   },
   "outputs": [],
   "source": [
    "# inplement all needed training functions\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWQrBZsQuQyR"
   },
   "outputs": [],
   "source": [
    "# use 3-fold cross-validation with random_state 42 to estimate model performance\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrCGrks_4V2e"
   },
   "outputs": [],
   "source": [
    "problem = \"SCHZ\"\n",
    "idx = np.argwhere((Y == problem) + (Y == \"CONTROL\")).ravel()\n",
    "tensor_latentvecs = data.dataset.TensorDataset(\n",
    "    torch.FloatTensor(Z[idx]),\n",
    "    torch.LongTensor(Y[idx] == problem)\n",
    ")\n",
    "# train on latentvectors dataset\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFnxJzon4V2q"
   },
   "outputs": [],
   "source": [
    "problem = \"BIPOLAR\"\n",
    "idx = np.argwhere((Y == problem) + (Y == \"CONTROL\")).ravel()\n",
    "tensor_latentvecs = data.dataset.TensorDataset(\n",
    "    torch.FloatTensor(Z[idx]),\n",
    "    torch.LongTensor(Y[idx] == problem)\n",
    ")\n",
    "# train on latentvectors dataset\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEwHCcRD4V2v"
   },
   "outputs": [],
   "source": [
    "problem = \"ADHD\"\n",
    "idx = np.argwhere((Y == problem) + (Y == \"CONTROL\")).ravel()\n",
    "tensor_latentvecs = data.dataset.TensorDataset(\n",
    "    torch.FloatTensor(Z[idx]),\n",
    "    torch.LongTensor(Y[idx] == problem)\n",
    ")\n",
    "# train on latentvectors dataset\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NEUROML2020_hw3_task3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
